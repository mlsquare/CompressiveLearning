{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0e81fd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 20), (6, 20))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "x_dim = 5\n",
    "y_dim = 6\n",
    "x_bits = 100\n",
    "y_bits = 100\n",
    "N = 20\n",
    "X = np.random.randn(x_dim, N)\n",
    "A= np.random.randn(y_dim,x_dim)\n",
    "Y= A@X\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50efddeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n",
      "(100, 6)\n"
     ]
    }
   ],
   "source": [
    "Phi_X = np.random.uniform(0, 1, (x_bits,x_dim))-0.5\n",
    "Phi_Y = np.random.uniform(0, 1, (y_bits,y_dim))-0.5\n",
    "print(Phi_X.shape)\n",
    "print(Phi_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ad4cd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20)\n",
      "(100, 20)\n"
     ]
    }
   ],
   "source": [
    "x_binary = np.sign( Phi_X@X)# Equals 'q' \n",
    "y_binary = np.sign( Phi_Y@Y)# Equals 'q' \n",
    "print(x_binary.shape)\n",
    "print(y_binary.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885daf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vt = np.linalg.svd(A, full_matrices=False)\n",
    "sqrt_S = np.sqrt(S)# Compute sqrt of sigma to adjust in U and Vt\n",
    "\n",
    "# Form the Values before projection\n",
    "U_s = U @ np.diag(sqrt_S)# Adjust sigma in U and Vt\n",
    "\n",
    "\n",
    "# Form the Keys before projection\n",
    "V_s = Vt.T @ np.diag(1/sqrt_S)# Adjust sigma in Vt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5c15994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(x, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Computes the Exponential Linear Unit (ELU) activation function.\n",
    "\n",
    "    Parameters:\n",
    "        x (array-like): Input data (scalar, vector, or matrix).\n",
    "        alpha (float): The alpha parameter controlling the saturation for x <= 0. Default is 1.0.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Transformed data after applying the ELU activation.\n",
    "    \"\"\"\n",
    "    return np.where(x > 0, x, alpha * (np.exp(x) - 1))\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Compute the softmax of vector x.\n",
    "    \n",
    "    Parameters:\n",
    "    x (numpy.ndarray): Input array.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Output array after applying softmax.\n",
    "    \"\"\"\n",
    "    # Subtract the max value from x for numerical stability\n",
    "    #x_max = np.max(x, axis=-1, keepdims=True)\n",
    "    #e_x = np.exp(x - x_max)\n",
    "    e_x = np.exp(x)\n",
    "    z = np.sum(e_x)\n",
    "    return e_x / z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f36e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values shape (100, 5)\n",
      "Keys Shape (100, 5)\n",
      "query shape (5, 1)\n",
      "query bits shape (100, 1)\n",
      "shape of attention (5, 1)\n",
      "[[  2.]\n",
      " [ 30.]\n",
      " [ 58.]\n",
      " [-32.]\n",
      " [-22.]]\n",
      "shape of y_bits predicted (100, 1)\n",
      "true bits:  [[ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "predicted bits:  [[-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]]\n",
      "bitwise accuracy 76.0\n",
      "total [[-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]]\n"
     ]
    }
   ],
   "source": [
    "Values = np.sign(Phi_Y@ U_s)\n",
    "print('Values shape',Values.shape)\n",
    "\n",
    "\n",
    "Keys = np.sign(Phi_X@ V_s)\n",
    "print('Keys Shape',Keys.shape)\n",
    "\n",
    "#x_query = X[:,0].reshape(-1,1)\n",
    "x_query = 0.1*V_s[:,1].reshape(-1,1) + 0.8*V_s[:,2].reshape(-1,1) - 0.3*V_s[:,3].reshape(-1,1)\n",
    "print('query shape',x_query.shape)\n",
    "\n",
    "x_query_bits = np.sign( Phi_X@x_query) \n",
    "print('query bits shape',x_query_bits.shape)\n",
    "\n",
    "y_true = A@x_query\n",
    "y_true_bits = np.sign( Phi_Y@y_true)\n",
    "\n",
    "attn = Keys.T@x_query_bits.reshape(-1,1)\n",
    "#elu_attn = softmax(attn)\n",
    "elu_attn = attn\n",
    "\n",
    "print('shape of attention',elu_attn.shape)\n",
    "print(elu_attn)\n",
    "\n",
    "y_true_bits_hat =  np.sign(Values@elu_attn)\n",
    "print('shape of y_bits predicted',y_true_bits_hat.shape)\n",
    "\n",
    "print('true bits: ', y_true_bits[:5])\n",
    "print('predicted bits: ', y_true_bits_hat[:5])\n",
    "\n",
    "print('bitwise accuracy',100*np.sum(y_true_bits_hat==y_true_bits)/len(y_true_bits_hat))\n",
    "\n",
    "print('total',y_true_bits_hat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#y_true_bits_hat = ?\n",
    "#y_true_hat = FISTA(y_true_bits_hat)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai839",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
