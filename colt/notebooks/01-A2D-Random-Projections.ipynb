{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../')) # or the path\n",
    "sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare two-moon data\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X,y  = make_moons(n_samples=200,noise=0.1, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "mm = make_pipeline(MinMaxScaler(), Normalizer())\n",
    "X_train = mm.fit_transform(X_train)\n",
    "X_test = mm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87        46\n",
      "           1       0.82      0.82      0.82        34\n",
      "\n",
      "    accuracy                           0.85        80\n",
      "   macro avg       0.85      0.85      0.85        80\n",
      "weighted avg       0.85      0.85      0.85        80\n",
      "\n",
      "acc is:  0.85\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = SGDClassifier(loss=\"log_loss\", alpha=0.01, max_iter=200, fit_intercept=False, penalty=None)\n",
    "\n",
    "# baseline\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# accuracy on test\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('acc is: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100)\n",
      "acc is:  0.85\n"
     ]
    }
   ],
   "source": [
    "# with Fourier features\n",
    "dim_in = X.shape[1]\n",
    "dim_feat = 100\n",
    "Phi = samples = np.random.normal(0, 1, size=(dim_in,dim_feat))\n",
    "print(Phi.shape)\n",
    "\n",
    "X_train_fourier = np.matmul(X_train,Phi)\n",
    "X_test_fourier = np.matmul(X_test,Phi)\n",
    "\n",
    "clf = SGDClassifier(loss=\"log_loss\", alpha=0.01, max_iter=200, fit_intercept=False, penalty=None)\n",
    "\n",
    "# baseline\n",
    "clf.fit(X_train_fourier,y_train)\n",
    "\n",
    "# accuracy on test\n",
    "y_pred = clf.predict(X_test_fourier)\n",
    "#print(classification_report(y_test, y_pred))\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('acc is: ', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 500) (500, 1)\n",
      "tx shape (120, 500)\n",
      "tau tile shape (120, 500)\n",
      "tx shape (80, 500)\n",
      "tau tile shape (80, 500)\n",
      "acc is:  0.75\n"
     ]
    }
   ],
   "source": [
    "# implement sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def quantile_tiles(x,phi, tau):\n",
    "    \n",
    "    dim_sample = x.shape[0]\n",
    "    dim_in = phi.shape[0]\n",
    "    dim_feat = phi.shape[1]\n",
    "    \n",
    "    \n",
    "    tau = np.reshape(tau,(1,dim_feat))\n",
    "    tau_tile = np.kron(np.ones((dim_sample,1)),tau)\n",
    "    x = np.matmul(x,phi)\n",
    "    print('tx shape',x.shape)\n",
    "    print('tau tile shape',tau_tile.shape)\n",
    "    x = sigmoid(x)\n",
    "    z = np.sign(x-tau_tile)\n",
    "    return z\n",
    "\n",
    "# repeat with quantiles-based random planes\n",
    "\n",
    "\n",
    "# with Fourier features\n",
    "dim_in = X.shape[1]\n",
    "dim_feat = 500\n",
    "Phi = np.random.normal(0, 1, size=(dim_in,dim_feat))\n",
    "Tau = np.random.uniform(size=(dim_feat,1))\n",
    "Tau = 0.5*np.ones((dim_feat,1))\n",
    "print(Phi.shape, Tau.shape)\n",
    "\n",
    "X_train_qt = quantile_tiles(X_train,Phi,Tau)\n",
    "X_test_qt = quantile_tiles(X_test,Phi,Tau)\n",
    "\n",
    "clf = SGDClassifier(loss=\"log_loss\", alpha=0.01, max_iter=500, fit_intercept=False, penalty=None)\n",
    "\n",
    "# baseline\n",
    "clf.fit(X_train_qt,y_train)\n",
    "\n",
    "# accuracy on test\n",
    "y_pred = clf.predict(X_test_qt)\n",
    "#print(classification_report(y_test, y_pred))\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('acc is: ', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80        46\n",
      "           1       0.71      0.85      0.77        34\n",
      "\n",
      "    accuracy                           0.79        80\n",
      "   macro avg       0.79      0.80      0.79        80\n",
      "weighted avg       0.80      0.79      0.79        80\n",
      "\n",
      "Logistic Regression Acc is:  0.7875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train_qt,y_train)\n",
    "y_pred = clf.predict(X_test_qt)\n",
    "# accuracy on test\n",
    "y_pred = clf.predict(X_test_qt)\n",
    "print(classification_report(y_test, y_pred))\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Logistic Regression Acc is: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8583333492279053\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from encoders import A2DLayer  # Import A2DLayer\n",
    "\n",
    "# Convert X_train and y_train to torch tensors\n",
    "data = torch.tensor(X_train, dtype=torch.float32)\n",
    "labels = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Build the classifier model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, **kwargs):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.encoder = A2DLayer(\n",
    "            in_features=input_size,\n",
    "            out_features=hidden_size,\n",
    "            **kwargs  # Pass A2DLayer parameters as kwargs\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Define A2DLayer parameters\n",
    "a2d_params = {\n",
    "    'pdf': 'normal',\n",
    "    'sign_fn': 'tanh',\n",
    "    'cdf_fn': 'sigmoid',\n",
    "    'quantile_tx': True,\n",
    "    'trainable': False\n",
    "}\n",
    "\n",
    "# Instantiate the model with A2DLayer parameters\n",
    "model = Classifier(\n",
    "    input_size=data.shape[1],\n",
    "    hidden_size=53,\n",
    "    **a2d_params  # Pass the params here\n",
    ")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the classifier\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(data)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    predictions = model(data)\n",
    "    predicted_labels = (predictions > 0.5).float()\n",
    "    accuracy = (predicted_labels == labels).float().mean()\n",
    "    print(\"Accuracy:\", accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([53, 2])\n",
      "Parameter containing:\n",
      "tensor([0.2854, 0.3046, 0.7308, 0.4346, 0.4871, 0.7520, 0.4713, 0.5606, 0.2365,\n",
      "        0.4399, 0.9327, 0.9329, 0.9569, 0.4511, 0.8281, 0.2691, 0.8794, 0.2606,\n",
      "        0.8221, 0.8527, 0.5098, 0.7567, 0.2630, 0.5927, 0.5935, 0.1203, 0.1157,\n",
      "        0.6415, 0.5036, 0.2830, 0.2230, 0.9103, 0.5743, 0.7862, 0.9858, 0.8879,\n",
      "        0.8686, 0.7487, 0.9658, 0.8910, 0.1236, 0.1748, 0.4280, 0.4498, 0.0924,\n",
      "        0.9692, 0.0435, 0.2254, 0.1050, 0.3653, 0.5765, 0.6773, 0.3423])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.encoder.linear.weight.data.shape)\n",
    "print(model.encoder.quantile_offset)\n",
    "print(model.encoder.linear.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.encoder.linear.weight.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai839",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
