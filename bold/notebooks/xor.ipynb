{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Variation\n",
    "\n",
    "Let in investigate a simple XOR gate based on AND, XOR, and OR primitives defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import pygad\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../')) # or the path\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***\n",
      "\n",
      "input:  -1 -1\n",
      "y:  -1\n",
      "model:  -1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 -1\n",
      "y:  -1\n",
      "model:  -1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 -1\n",
      "y:  -1\n",
      "model:  1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 -1\n",
      "y:  -1\n",
      "model:  1 1\n",
      "model is WRONG.\n",
      "# 2 and got UPDATED +++\n",
      "model after:  [-1, -1]\n",
      "pred before:  1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 1\n",
      "y:  -1\n",
      "model:  -1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 1\n",
      "y:  -1\n",
      "model:  -1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 1\n",
      "y:  -1\n",
      "model:  1 -1\n",
      "model is WRONG.\n",
      "# 2 and got UPDATED +++\n",
      "model after:  [-1, 1]\n",
      "pred before:  1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 1\n",
      "y:  -1\n",
      "model:  1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 -1\n",
      "y:  -1\n",
      "model:  -1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 -1\n",
      "y:  -1\n",
      "model:  -1 1\n",
      "model is WRONG.\n",
      "# 2 and got UPDATED +++\n",
      "model after:  [1, -1]\n",
      "pred before:  1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 -1\n",
      "y:  -1\n",
      "model:  1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 -1\n",
      "y:  -1\n",
      "model:  1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 1\n",
      "y:  -1\n",
      "model:  -1 -1\n",
      "model is WRONG.\n",
      "# 2 and got UPDATED +++\n",
      "model after:  [1, 1]\n",
      "pred before:  1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 1\n",
      "y:  -1\n",
      "model:  -1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 1\n",
      "y:  -1\n",
      "model:  1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 1\n",
      "y:  -1\n",
      "model:  1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 -1\n",
      "y:  1\n",
      "model:  -1 -1\n",
      "model is WRONG.\n",
      "but NOT UPDATED ---\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 -1\n",
      "y:  1\n",
      "model:  -1 1\n",
      "model is WRONG.\n",
      "# 1 and got UPDATED +++\n",
      "model after:  [1, 1]\n",
      "pred before:  -1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 -1\n",
      "y:  1\n",
      "model:  1 -1\n",
      "model is WRONG.\n",
      "# 1 and got UPDATED +++\n",
      "model after:  [1, 1]\n",
      "pred before:  -1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 -1\n",
      "y:  1\n",
      "model:  1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 1\n",
      "y:  1\n",
      "model:  -1 -1\n",
      "model is WRONG.\n",
      "# 1 and got UPDATED +++\n",
      "model after:  [1, -1]\n",
      "pred before:  -1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 1\n",
      "y:  1\n",
      "model:  -1 1\n",
      "model is WRONG.\n",
      "but NOT UPDATED ---\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 1\n",
      "y:  1\n",
      "model:  1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 1\n",
      "y:  1\n",
      "model:  1 1\n",
      "model is WRONG.\n",
      "# 1 and got UPDATED +++\n",
      "model after:  [1, -1]\n",
      "pred before:  -1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 -1\n",
      "y:  1\n",
      "model:  -1 -1\n",
      "model is WRONG.\n",
      "# 1 and got UPDATED +++\n",
      "model after:  [-1, 1]\n",
      "pred before:  -1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 -1\n",
      "y:  1\n",
      "model:  -1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 -1\n",
      "y:  1\n",
      "model:  1 -1\n",
      "model is WRONG.\n",
      "but NOT UPDATED ---\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 -1\n",
      "y:  1\n",
      "model:  1 1\n",
      "model is WRONG.\n",
      "# 1 and got UPDATED +++\n",
      "model after:  [-1, 1]\n",
      "pred before:  -1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 1\n",
      "y:  1\n",
      "model:  -1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 1\n",
      "y:  1\n",
      "model:  -1 1\n",
      "model is WRONG.\n",
      "# 1 and got UPDATED +++\n",
      "model after:  [-1, -1]\n",
      "pred before:  -1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 1\n",
      "y:  1\n",
      "model:  1 -1\n",
      "model is WRONG.\n",
      "# 1 and got UPDATED +++\n",
      "model after:  [-1, -1]\n",
      "pred before:  -1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 1\n",
      "y:  1\n",
      "model:  1 1\n",
      "model is WRONG.\n",
      "but NOT UPDATED ---\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "total mistakes:  4 out of 32\n"
     ]
    }
   ],
   "source": [
    "from engine import Bool\n",
    "from bnn import ProdTron, SumTron, ProdLayer, SumLayer\n",
    "\n",
    "# can we learn an xor gate?\n",
    "def optim_xor(x,w,y):\n",
    "    h = [ xi^wi for xi, wi in zip(x,w)]\n",
    "    yh = np.prod(h) # \n",
    "    yhd = [yh.data]\n",
    "    \n",
    "    # run one iteration of GD\n",
    "    loss = y^yh # xor between observed and predicted\n",
    "    loss.backward()\n",
    "\n",
    "    flips = 0\n",
    "\n",
    "    # for this specific case, gradient update takes this form\n",
    "    for wi in w:\n",
    "        if wi.grad == wi.data:\n",
    "            flips += 1\n",
    "            wi.data = -wi.data\n",
    "    \n",
    "    # re-eval the gate\n",
    "    h = [ xi^wi for xi, wi in zip(x,w)]\n",
    "    yh = np.prod(h) #\n",
    "    yhd.append(yh.data)\n",
    "\n",
    "    mistake = 0\n",
    "\n",
    "    if loss.data<0:\n",
    "        print('model is CORRECT')    \n",
    "        if flips>0:\n",
    "            print('#',flips,'BUT got updated ---')\n",
    "            print('model after: ',[wi.data for wi in w])\n",
    "            mistake += 1\n",
    "        else:\n",
    "            print('and NOT updated +++')\n",
    "    else:\n",
    "        print('model is WRONG.') \n",
    "        if flips>0:\n",
    "            print('#',flips,'and got UPDATED +++')\n",
    "            print('model after: ',[wi.data for wi in w])\n",
    "        else:\n",
    "            mistake +=1\n",
    "            print('but NOT UPDATED ---')\n",
    "    \n",
    "    print('pred before: ',yhd[0],'\\npred  after: ',yhd[1])\n",
    "    return w,yhd,flips,mistake\n",
    "\n",
    "\n",
    "import itertools\n",
    "T = [-1,1]\n",
    "mistakes = 0\n",
    "for element in itertools.product(T, repeat=5):\n",
    "    print('\\n***\\n')\n",
    "    y = Bool(element[0])\n",
    "    x = [Bool(element[1]),Bool(element[2])]\n",
    "    w = [Bool(element[3]),Bool(element[4])]\n",
    "    print('input: ',x[0].data, x[1].data)\n",
    "    print('y: ',y.data)\n",
    "    print('model: ',w[0].data, w[1].data)\n",
    "    w,yhd,flips,mistake = optim_xor(x,w,y)\n",
    "    mistakes += mistake\n",
    "print('total mistakes: ', mistakes, 'out of', np.power(2,5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term we want to model is $x_1 \\neg x_2$ or $\\neg x_1 x_2$. What we notice is, gradients are not defined (or ignored) when needed (model is wrong) in some specific cases. \n",
    "\n",
    "That is, when $x_i=w_i$ and $x_1=x_2$, the model is $AND(\\neg x_1 \\neg x_2) = F$. Local gradient of $AND(.,.)$ is 0 in this case.\n",
    "\n",
    "This seems like a problem. When no other signal is present (for particular combination of inputs, model weights, and label to model), model updates can not happen via backprop.\n",
    "\n",
    "Do we need to modify the definitions of the gradient operator and/or the definition of the gates.\n",
    "\n",
    "For example, based on the definition according to BOLD, \n",
    "\n",
    "$AND(x,0) =0 \\forall x$. But this can be modified as follows.\n",
    "\n",
    "In fact, when $x = T \\equiv x > 0$, we could have affirmatively defined the gradient to be $AND(x,0) = T \\text{ when } x=T$. But when $x < 0$, it is undecidable and information from the other input is needed to determine the quadrant. May be we can throw a coin to decide. At least, in expectation, we will be right.\n",
    "\n",
    "So, the modified gates with extended Boolean space , with fuzzy o/p, can be defined as:\n",
    "\n",
    "**Fuzzy AND gate**\n",
    "\n",
    "| $x_1$ | $x_2$ | $y_{AND}$ | \n",
    "|-----|-----|-----|\n",
    "T| T | T | \n",
    "T| F | F |\n",
    "F| T | F | \n",
    "F| F | F |\n",
    "T| 0 | T |\n",
    "F| 0 | $\\text{Bernoulli}(0.5)$ |\n",
    "0| T | T |\n",
    "0| F | $\\text{Bernoulli}(0.5)$ |\n",
    "0| 0 | $\\text{Bernoulli}(0.5)$ |\n",
    "\n",
    "As a result, $AND(x_1,x_2) \\in   \\{T,F\\} \\forall x \\in \\{T,0,F\\}$, i.e.,  even if any of the inputs are 0, by definition, AND gate is not 0.\n",
    "\n",
    "We need to extend this to $XNOR$ gate, as the derivative involves $XNOR$ gate.\n",
    "\n",
    "**Fuzzy XNOR gate**\n",
    "\n",
    "| $x_1$ | $x_2$ | $y_{XOR}$ | \n",
    "|-----|-----|-----|\n",
    "T| T | T | \n",
    "T| F | F |\n",
    "F| T | F | \n",
    "F| F | T |\n",
    "T/F| 0 | $\\text{Bernoulli}(0.5)$ |\n",
    "0| T/F | $\\text{Bernoulli}(0.5)$ |\n",
    "0| 0 | $\\text{Bernoulli}(0.5)$ |\n",
    "\n",
    "#### Derivative of AND\n",
    "\n",
    "Recall:\n",
    "1. $\\delta(a \\to b) \\equiv True$ if $b > a$, $\\equiv 0$ if $b = a$, and $\\equiv False$ if $b < a$.\n",
    "2. $f'(x) \\equiv \\text{xnor}(\\delta(x \\to \\neg x), \\delta f(x \\to \\neg x))$.\n",
    "\n",
    "The Truth Table for $f(x) = f_a(x) = AND(x,a)$ is:\n",
    "\n",
    "| $a$ | $x$ | $\\neg x$ | $\\delta x$ | $f(x)$ |$f(\\neg x)$ |  $\\delta f$ | $f'$ \n",
    "|-----|-----|-----|-----| -----| -----|-----|-----|\n",
    "T| T | F | F | T | F | F | T | \n",
    "T| F | T | T | F | T | T | T | \n",
    "F| T | F | F | F | F | 0 | $\\text{Bernoulli}(0.5)$ | |\n",
    "F| F | T | T | F | F | 0 | $\\text{Bernoulli}(0.5)$ | |\n",
    "\n",
    "Therefore, $f'_{a}(x) \\in \\mathcal{B} \\forall a,x \\in \\mathcal{B}$. Effectively, when the output can not be decided, we toss a fair coin decide. Once we ensure that logic gates are in $\\mathcal{B}$, we do not encounter the problem we saw with the definitions according to BOLD.\n",
    "\n",
    "But before we go this route, we have another question. To learn the expression, will contrastive examples be sufficient. Let us explore this next.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***\n",
      "\n",
      "input:  -1 -1\n",
      "y:  -1\n",
      "model:  -1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 1\n",
      "y:  -1\n",
      "model:  -1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 -1\n",
      "y:  1\n",
      "model:  -1 -1\n",
      "model is WRONG.\n",
      "# 1 and got UPDATED +++\n",
      "model after:  [-1, 1]\n",
      "pred before:  -1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 1\n",
      "y:  -1\n",
      "model:  -1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "[data:-1, grad:1, data:1, grad:-2]\n",
      "\n",
      "***\n",
      "\n",
      "correct\n",
      "\n",
      "***\n",
      "\n",
      "correct\n",
      "\n",
      "***\n",
      "\n",
      "correct\n",
      "\n",
      "***\n",
      "\n",
      "correct\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# we want to realize x1*x2' term. The truth table for this term is\n",
    "T = [[-1,-1,-1],[-1,1,-1],[1,-1,1],[1,1,-1]]\n",
    "\n",
    "mistakes = 0\n",
    "w = [Bool(-1),Bool(-1)]\n",
    "\n",
    "# for some rows in the truth table, this model is wrong\n",
    "# by looping through other data, will we be able to eventually update the model?\n",
    "\n",
    "for element in T:\n",
    "    print('\\n***\\n')\n",
    "    x = [Bool(element[0]),Bool(element[1])]\n",
    "    y = Bool(element[2])    \n",
    "    print('input: ',x[0].data, x[1].data)\n",
    "    print('y: ',y.data)\n",
    "    print('model: ',w[0].data, w[1].data)\n",
    "    w,yhd,flips,mistake = optim_xor(x,w,y)\n",
    "    mistakes += mistake\n",
    "# final model\n",
    "print(w)\n",
    "\n",
    "# see if it is correct for all inputs\n",
    "for element in T:\n",
    "    print('\\n***\\n')\n",
    "    x = [Bool(element[0]),Bool(element[1])]\n",
    "    yh = np.prod([ xi^wi for xi, wi in zip(x,w)])\n",
    "    if yh.data == element[2]:\n",
    "        print('correct')\n",
    "    else:\n",
    "        print('wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***\n",
      "\n",
      "input:  -1 -1\n",
      "y:  -1\n",
      "model:  -1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 1\n",
      "y:  -1\n",
      "model:  -1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 -1\n",
      "y:  1\n",
      "model:  -1 -1\n",
      "model is WRONG.\n",
      "# 1 and got UPDATED +++\n",
      "model after:  [-1, 1]\n",
      "pred before:  -1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 1\n",
      "y:  -1\n",
      "model:  -1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "# mistakes 0\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 -1\n",
      "y:  -1\n",
      "model:  -1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 1\n",
      "y:  -1\n",
      "model:  -1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 -1\n",
      "y:  1\n",
      "model:  -1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 1\n",
      "y:  -1\n",
      "model:  -1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "# mistakes 0\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 -1\n",
      "y:  -1\n",
      "model:  1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 1\n",
      "y:  -1\n",
      "model:  1 -1\n",
      "model is WRONG.\n",
      "# 1 and got UPDATED +++\n",
      "model after:  [-1, -1]\n",
      "pred before:  1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 -1\n",
      "y:  1\n",
      "model:  -1 -1\n",
      "model is WRONG.\n",
      "# 1 and got UPDATED +++\n",
      "model after:  [-1, 1]\n",
      "pred before:  -1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 1\n",
      "y:  -1\n",
      "model:  -1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "# mistakes 0\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 -1\n",
      "y:  -1\n",
      "model:  -1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  -1 1\n",
      "y:  -1\n",
      "model:  -1 -1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 -1\n",
      "y:  1\n",
      "model:  -1 -1\n",
      "model is WRONG.\n",
      "# 1 and got UPDATED +++\n",
      "model after:  [-1, 1]\n",
      "pred before:  -1 \n",
      "pred  after:  1\n",
      "\n",
      "***\n",
      "\n",
      "input:  1 1\n",
      "y:  -1\n",
      "model:  -1 1\n",
      "model is CORRECT\n",
      "and NOT updated +++\n",
      "pred before:  -1 \n",
      "pred  after:  -1\n",
      "# mistakes 0\n",
      "Truth Table can be learnt if all entire Truth Table is seen by the model\n"
     ]
    }
   ],
   "source": [
    "# we should verify this for all different initializations of the weights\n",
    "\n",
    "# we want to realize x1*x2' term. The truth table for this term is\n",
    "T = [[-1,-1,-1],[-1,1,-1],[1,-1,1],[1,1,-1]]\n",
    "W = [[-1,-1],[-1,1],[1,-1],[-1,-1]]\n",
    "\n",
    "mistakes = 0\n",
    "w = [Bool(-1),Bool(-1)]\n",
    "flag = False\n",
    "# for some rows in the truth table, this model is wrong\n",
    "# by looping through other data, will we be able to eventually update the model?\n",
    "for wi in W:\n",
    "    w = [Bool(wi[0]),Bool(wi[-1])]\n",
    "    for element in T:\n",
    "        print('\\n***\\n')\n",
    "        x = [Bool(element[0]),Bool(element[1])]\n",
    "        y = Bool(element[2])    \n",
    "        print('input: ',x[0].data, x[1].data)\n",
    "        print('y: ',y.data)\n",
    "        print('model: ',w[0].data, w[1].data)\n",
    "        w,yhd,flips,mistake = optim_xor(x,w,y)\n",
    "        mistakes += mistake\n",
    "    print('# mistakes',mistakes)    \n",
    "    \n",
    "    # see if it is correct for all inputs\n",
    "    for element in T:\n",
    "        x = [Bool(element[0]),Bool(element[1])]\n",
    "        yh = np.prod([ xi^wi for xi, wi in zip(x,w)])\n",
    "        if yh.data != element[2]:\n",
    "            flag = True\n",
    "            print('-- Failed --')\n",
    "if flag:\n",
    "    print('Truth Table can not learnt')\n",
    "else:\n",
    "    print('Truth Table can be learnt if all entire Truth Table is seen by the model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implication is, entire Truth Table must be shown to the optimizer for updating the weights.\n",
    "However, when only single \"example\" is given, and model is wrong for that example - that error signal is not enough. It depends on the Truth Table state for that particular input to flip the model weights.\n",
    "\n",
    "When such gates are present in millions in neural networks, the opportunity to be in a bad state grow exponentially. \n",
    "Therefore, either we have to update the gradient definition to be decideable or we have to use the gradients as \"noisy signal\" to drive the errors to be smaller, but can get stuck occasionally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Consider an 2-ary MLP that is modeling an XOR Gate. For a certain combination of input and model weights, gradients are not decidable, arising from the decidability of the primitive Gates. \n",
    "\n",
    "Gradients, defined according to BOLD, are undecidable when any of its inputs are 0 (to be ignored). This impacts the feedback loop to control the error.\n",
    "\n",
    "How often can this happen? Does this depend on the topology of the network?\n",
    "\n",
    "Specifically, any term in the 2-ary XOR Gate will take the form  $AND(XOR(x_1,w_1),XOR(x_2,w_2))$. Note the NOT gate is actually an XOR gate. $XOR(x,T)=\\neg x = NOT(x)$, $XOR(x,F) = x$. Therefore, with this 2-ary MLP, we can model any 2-ary Product terms of the SoP, which forms the backbone to model much general Truth Tables.\n",
    "\n",
    "When $x_i=w_i \\, \\& \\, x_1=x_2$, the model is $AND(\\neg x_1 \\neg x_2) = F$ for $x_i = T$. Local gradient of $AND(.,.)$ is 0 in this case. Therefore, error will not propagate backwards.\n",
    "\n",
    "Now consider an K-ary MLP formed of 2-ary MLP (of the form above) that is both  deep and wide, randomly initialized. For the sake of discussion consider the architecture of constant width of $H$, with depth $D$ (not including the input and output layers). This network has $P = 2(KH + DH^2 + H)$. As a result, the network will have $2^P$ possible initial states. \n",
    "\n",
    "Of the $2^K$ possible inputs, $2^P$ random configurations, how many rows of the Truth Table can not be learnt with a single backprop iteration?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai839",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
